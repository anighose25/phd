{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import date\n",
    "from datetime import datetime,timedelta\n",
    "import plotly.figure_factory as ff\n",
    "from copy import deepcopy\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from os import path\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#JUST CHANGE THIS CELL AND RUN ALL OTHERS Experiment 1 = Static Scheduling for Transformer, Experiment 2 = Clustering v/s Eager, Experiment 3 = Clustering v/s HEFT\n",
    "HOME = \"./desktop/\"\n",
    "PREFIX = \"\"\n",
    "EXPERIMENT = 1 #any one of 1,2,3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EXPERIMENT == 1:\n",
    "    expt = \"\"\n",
    "else:\n",
    "    folder = \"Expt-2\"\n",
    "    if EXPERIMENT == 2:\n",
    "        heft_version = \"eager\"\n",
    "    elif EXPERIMENT == 3:\n",
    "        heft_version = \"dynamic\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_relative_timestamps(size,num_queues_gpu=0,num_queues_cpu=0,num_heads_on_cpu=0,dag=\"transformer\",heft=False,heft_version=\"eager\"):\n",
    "    timestamps=None\n",
    "    if not heft:\n",
    "        if num_queues_gpu==1 and num_queues_cpu==1:\n",
    "            if dag==\"transformer\":\n",
    "                size = 2**size\n",
    "            filename=None\n",
    "            filename = PREFIX+HOME+\"final_cq_experiments/coarse/coarse_{}_{}.json\".format(dag,size)\n",
    "            with open(filename) as f:\n",
    "                timestamps = json.load(f)\n",
    "        else:\n",
    "            if dag==\"transformer\":\n",
    "                size = 2**size\n",
    "            filename = PREFIX+HOME+\"final_cq_experiments/q_assignment_{}_{}_{}.json\".format(dag,size,num_heads_on_cpu)\n",
    "#             print \"Opening \",filename\n",
    "            with open(filename) as f:\n",
    "                timestamps = json.load(f)\n",
    "\n",
    "        \n",
    "       \n",
    "  \n",
    "#     else:\n",
    "#         num_heads=0\n",
    "#         if dag==\"transformer\":\n",
    "#             size = 2**size\n",
    "#             num_heads=16\n",
    "#         if dag==\"siamese\":\n",
    "#             num_heads=2\n",
    "#         if dag==\"resnext\":\n",
    "#             num_heads=32\n",
    "        \n",
    "            \n",
    "            \n",
    "    elif heft_version == \"eager\":\n",
    "        num_heads=0\n",
    "        if dag==\"transformer\":\n",
    "            size = 2**size\n",
    "            num_heads=16\n",
    "        if dag==\"siamese\":\n",
    "            num_heads=2\n",
    "        if dag==\"resnext\":\n",
    "            num_heads=32\n",
    "        filename = PREFIX+HOME+\"coarse_experiments/eager_{}_{}_with_delays.json\".format(dag,size)\n",
    "        print \"Opening\",filename\n",
    "        with open(filename) as f:\n",
    "            timestamps = json.load(f)\n",
    "    elif heft_version == \"dynamic\":\n",
    "        num_heads=0\n",
    "        if dag==\"transformer\":\n",
    "            size = 2**size\n",
    "            num_heads=16\n",
    "        if dag==\"siamese\":\n",
    "            num_heads=2\n",
    "        if dag==\"resnext\":\n",
    "            num_heads=32\n",
    "        filename = PREFIX+HOME+\"coarse_experiments/dheft_{}_{}_with_delays.json\".format(dag,size)\n",
    "        print \"Opening \",filename\n",
    "        with open(filename) as f:\n",
    "            timestamps = json.load(f)\n",
    "\n",
    "    kernels = timestamps.keys()\n",
    "    reference_device = {}\n",
    "    reference_host = {}\n",
    "    total_time = 0\n",
    "    global_reference = None\n",
    "\n",
    "    for kernel in kernels:\n",
    "        device = timestamps[kernel][\"device\"]\n",
    "        if device == 'gpu':\n",
    "            t = timestamps[kernel][\"write\"][\"device_start\"]\n",
    "        else:\n",
    "            t = timestamps[kernel][\"nd_range\"][\"device_start\"]\n",
    "        if t == -1:\n",
    "            continue\n",
    "        if not (device in reference_device):\n",
    "            reference_device[device] = t\n",
    "        else:\n",
    "            reference_device[device] = min(reference_device[device],t)\n",
    "\n",
    "        t = timestamps[kernel][\"write\"][\"host_queued_end\"]\n",
    "\n",
    "        if not (device in reference_host):\n",
    "            reference_host[device] = t\n",
    "        else:\n",
    "            reference_host[device] = min(reference_host[device],t)\n",
    "\n",
    "        t = timestamps[kernel][\"write\"][\"host_queued_start\"]\n",
    "        #print timestamps[kernel][\"write\"][\"host_queued_end\"]-timestamps[kernel][\"write\"][\"host_queued_start\"]\n",
    "        if not global_reference:\n",
    "            global_reference = t\n",
    "        else:\n",
    "            global_reference = min(global_reference,t)\n",
    "\n",
    "    relative_timestamps = deepcopy(timestamps)\n",
    "\n",
    "    # global_reference = None\n",
    "\n",
    "    # for key,value in reference_host.items():\n",
    "    #     if not global_reference:\n",
    "    #         global_reference = value\n",
    "    #     else:\n",
    "    #         global_reference = min(value,global_reference)\n",
    "\n",
    "\n",
    "    for kernel,kernel_timestamps in relative_timestamps.items():\n",
    "        device = kernel_timestamps[\"device\"]\n",
    "        for event_type,event_timestamps in kernel_timestamps.items():\n",
    "            #print(event_type)\n",
    "            if event_type in [\"device\",\"cmdq\"]:\n",
    "                continue\n",
    "            else:\n",
    "                #continue\n",
    "                for sub_event_type in event_timestamps:\n",
    "                    if  sub_event_type[:4] == \"host\":\n",
    "                        event_timestamps[sub_event_type] -= global_reference\n",
    "                        continue\n",
    "                    else:\n",
    "                       event_timestamps[sub_event_type] = event_timestamps[sub_event_type] - reference_device[device] + reference_host[device] - global_reference\n",
    "    #                     event_timestamps[sub_event_type] = event_timestamps[sub_event_type] - reference_device[device] + \\\n",
    "    #                     kernel_timestamps[\"write\"][\"host_queued_start\"] - global_reference\n",
    "                    total_time = max(total_time,event_timestamps[sub_event_type])\n",
    "\n",
    "\n",
    "\n",
    "    #print \"Total Time Taken - \",total_time\n",
    "    #print(json.dumps(relative_timestamps,sort_keys=True,indent=1))          \n",
    "    return total_time,relative_timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOME=\"./cluster/\"\n",
    "def get_queues(dag,size,num_heads_on_cpu,key):\n",
    "    if dag==\"transformer\":\n",
    "        size=2**size\n",
    "    filename = PREFIX+HOME+\"setup_cq_experiments/q_assignment_{}_{}_{}.stats\".format(dag,size,num_heads_on_cpu)\n",
    "    queues={'cpu':0,'gpu':0}\n",
    "    contents=open(filename,'r').readlines()\n",
    "    for line in contents:\n",
    "        dtype,num_queues=line.strip(\"\\n\").split(\",\")\n",
    "        queues[dtype]=num_queues\n",
    "    return int(queues[key])\n",
    "\n",
    "def get_enq_times(dag,size,num_heads_on_cpu):\n",
    "    if dag==\"transformer\":\n",
    "        size=2**size\n",
    "    filename = PREFIX+HOME+\"setup_cq_experiments/q_assignment_{}_{}_{}.time\".format(dag,size,num_heads_on_cpu)\n",
    "#     print \"Opening \",filename\n",
    "    queues={'cpu':0,'gpu':0}\n",
    "    contents=open(filename,'r').readlines()\n",
    "    total_time=0.0\n",
    "    for line in contents:\n",
    "#         print line\n",
    "        dtype,num_queues=line.strip(\"\\n\").split(\",\")\n",
    "        total_time+=float(num_queues)\n",
    "    return total_time\n",
    "\n",
    "# get_queues(\"siamese\",64,2,'cpu')\n",
    "# get_enq_times(\"transformer\",7,1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_time(dag,size,num_heads):\n",
    "    \n",
    "    gains = []\n",
    "    sizes = []\n",
    "    gpu_queues = []\n",
    "    cpu_queues = []\n",
    "    best_times = []\n",
    "\n",
    "   \n",
    "\n",
    "    ul=num_heads    \n",
    "    min_time = None\n",
    "    min_config = {}\n",
    "    all_configs = {}\n",
    "\n",
    "    default,_ = create_relative_timestamps(size,num_queues_gpu=1,num_queues_cpu=1,num_heads_on_cpu=0,dag=dag)\n",
    "    for num_heads_on_cpu in range(0,ul):\n",
    "        try:\n",
    "            total_time,_ = create_relative_timestamps(size,num_heads_on_cpu=num_heads_on_cpu,dag=dag)\n",
    "#             print \"Individual\",dag,size,num_heads_on_cpu,total_time\n",
    "            all_configs[(size,num_heads_on_cpu)] = total_time\n",
    "            if (not min_time) or (total_time<min_time):\n",
    "                min_time = total_time\n",
    "                min_config['num_heads_on_cpu'] = num_heads_on_cpu\n",
    "                min_config['num_queues_gpu'] = get_queues(dag,size,num_heads_on_cpu,'gpu')\n",
    "                min_config['num_queues_cpu'] = get_queues(dag,size,num_heads_on_cpu,'cpu')\n",
    "#                 min_config['enq_time']=get_enq_times(dag,size,num_heads_on_cpu)\n",
    "\n",
    "            #print \"Num Queues - GPU {} CPU {} CPU Heads {}/{} Total Time {}\".format(num_queues_gpu,num_queues_cpu,num_heads_on_cpu,size,total_time)\n",
    "        except KeyboardInterrupt:\n",
    "            raise KeyboardInterrupt\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "            #print \"Best Configuration for size {} is {}, %gain {}\".format(size,min_config,100.0*(default-min_time)/default)\n",
    "            #raise e\n",
    "    gain = 100.0*(default-min_time)/default\n",
    "\n",
    "#     if EXPERIMENT==1:\n",
    "#         print \"Best Configuration for number of heads {} and size {} is {}, %gain {}\".format(num_heads,size,min_config,gain)\n",
    "#     else:\n",
    "#         print \"Best Configuration for size {} and number of heads 16 is {}, %time {}\".format(2**size,min_config,min_time)\n",
    "\n",
    "    \n",
    "    \n",
    "    best_time = min_time\n",
    "    gpu_queues = min_config['num_queues_gpu']\n",
    "    cpu_queues = min_config['num_queues_cpu']\n",
    "    final_heads_on_cpu = min_config['num_heads_on_cpu']\n",
    "#     enq_time = min_config['enq_time']\n",
    "#     print dag,size,num_heads, final_heads_on_cpu, gpu_queues,cpu_queues, gain,(enq_time/best_time)*100,\"%\"\n",
    "    print dag,size,num_heads, final_heads_on_cpu, gpu_queues,cpu_queues, default,best_time, gain\n",
    "    return final_heads_on_cpu,gpu_queues,cpu_queues,float(default)/best_time,best_time,default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dag     size total_subdags subdags_on_cpu  ngpu ncpu gain algo\n",
      "./desktop/\n",
      "siamese 64 2 0 3 0 0.00553464889526 0.00550103187561 0.60739209098\n",
      "siamese 128 2 0 3 0 0.00616812705994 0.00606274604797 1.70847667272\n",
      "siamese 256 2 0 3 0 0.00821685791016 0.00786590576172 4.27112349118\n",
      "transformer 6 16 2 5 2 0.051210641861 0.0478324890137 6.59658368755\n",
      "transformer 7 16 1 5 2 0.0715758800507 0.0636732578278 11.0409012328\n",
      "transformer 8 16 1 5 2 0.173897504807 0.144001722336 17.1916109457\n",
      "transformer 9 16 1 5 2 0.679745912552 0.598903179169 11.8930812073\n",
      "resnext 64 32 0 3 0 0.374226093292 0.321209192276 14.1670775947\n",
      "resnext 128 32 0 3 0 0.695518016815 0.585152864456 15.8680508183\n",
      "resnext 256 32 3 3 2 1.32172656059 1.10415935516 16.4608332703\n",
      "./cluster/\n",
      "siamese 64 2 0 3 0 0.0124390125275 0.012241601944 1.58702777299\n",
      "siamese 128 2 1 3 1 0.0146851539612 0.0146169662476 0.464330941325\n",
      "siamese 256 2 1 3 1 0.0179741382599 0.0166325569153 7.46395362719\n",
      "transformer 6 16 0 5 0 0.12570977211 0.0815200805664 35.1521530919\n",
      "transformer 7 16 3 5 5 0.114284515381 0.100336074829 12.2050135185\n",
      "transformer 8 16 4 5 5 0.290144681931 0.185587644577 36.0361722496\n",
      "transformer 9 16 5 5 5 0.929095506668 0.593644618988 36.1051027879\n",
      "resnext 64 32 16 4 2 0.460395812988 0.278021097183 39.6125921783\n",
      "resnext 128 32 15 4 2 0.794471502304 0.444513082504 44.0492099194\n",
      "resnext 256 32 14 3 2 1.49891448021 0.809017896652 46.0264139593\n"
     ]
    }
   ],
   "source": [
    "workloads = [\"siamese\", \"transformer\" , \"resnext\"]\n",
    "# workloads = [\"resnext\"]\n",
    "# home=[\"./cluster/\"]\n",
    "home = [\"./desktop/\",\"./cluster/\"]\n",
    "HOME = \"./desktop/\"\n",
    "best_time_config = {}\n",
    "print \"dag     size total_subdags subdags_on_cpu  ngpu ncpu gain algo\"\n",
    "for h in home:\n",
    "    print h\n",
    "    HOME=h\n",
    "    for workload in workloads:\n",
    "        if workload==\"transformer\":\n",
    "            for size in [6,7,8,9]:\n",
    "                best_time_config[(h,workload,size)]=get_best_time(\"transformer\",size,16)\n",
    "        if workload==\"siamese\":\n",
    "            for size in [64,128,256]:\n",
    "                best_time_config[(h,workload,size)]=get_best_time(\"siamese\",size,2)\n",
    "        if workload==\"resnext\":\n",
    "            for size in [64,128,256]:\n",
    "                best_time_config[(h,workload,size)]=get_best_time(\"resnext\",size,32)\n",
    "# print best_time_config\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get mapping sensitivity\n",
    "import numpy as np\n",
    "def get_mapping_sensitivity(dag,size,num_heads,num_heads_on_cpu):\n",
    "    \n",
    "    gains = []\n",
    "    sizes = []\n",
    "    gpu_queues = []\n",
    "    cpu_queues = []\n",
    "    best_times = []\n",
    "\n",
    "   \n",
    "\n",
    "    ul=num_heads_on_cpu    \n",
    "    min_time = None\n",
    "    min_config = {}\n",
    "    all_configs = {}\n",
    "#     print dag,size\n",
    "    default,_ = create_relative_timestamps(size,num_queues_gpu=1,num_queues_cpu=1,num_heads_on_cpu=0,dag=dag)\n",
    "\n",
    "    all_times = []\n",
    "    for num_queues_gpu in range(1,6):\n",
    "        for num_queues_cpu in range(1,6):\n",
    "            try:\n",
    "                total_time,_ = create_relative_timestamps(size,num_queues_gpu,num_queues_cpu,num_heads_on_cpu,dag=dag)\n",
    "                print num_heads_on_cpu,num_queues_cpu,num_queues_gpu,total_time\n",
    "                all_configs[(size,num_queues_cpu,num_queues_gpu,num_heads_on_cpu)] = total_time\n",
    "                all_times.append(total_time)\n",
    "\n",
    "\n",
    "                #print \"Num Queues - GPU {} CPU {} CPU Heads {}/{} Total Time {}\".format(num_queues_gpu,num_queues_cpu,num_heads_on_cpu,size,total_time)\n",
    "            except KeyboardInterrupt:\n",
    "                raise KeyboardInterrupt\n",
    "            except Exception as e:\n",
    "                raise e\n",
    "                #print \"Best Configuration for size {} is {}, %gain {}\".format(size,min_config,100.0*(default-min_time)/default)\n",
    "                #raise e\n",
    "    st = np.std(all_times)\n",
    "#     print \"Variance for num_heads on cpu {}: {}\".format(num_heads_on_cpu,st)\n",
    "    return st\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('./cluster/', 'siamese', 256): (1, 3, 1, 1.1906482038932371, 0.016632556915283203), ('./desktop/', 'transformer', 9): (1, 5, 2, 1.1157743168541814, 0.5989031791687012), ('./desktop/', 'siamese', 64): (0, 3, 0, 0.9965327438997963, 0.0055010318756103516), ('./desktop/', 'transformer', 7): (1, 5, 2, 1.111351169191021, 0.06367325782775879), ('./cluster/', 'transformer', 8): (4, 5, 5, 1.6219683432017276, 0.18558764457702637), ('./desktop/', 'transformer', 8): (1, 5, 2, 1.2118538975176618, 0.14400172233581543), ('./desktop/', 'transformer', 6): (2, 5, 2, 1.0559354812983492, 0.047832489013671875), ('./cluster/', 'resnext', 256): (19, 4, 2, 1.8135861155022628, 0.8581662178039551), ('./cluster/', 'siamese', 64): (0, 3, 0, 0.9846723147336645, 0.012241601943969727), ('./desktop/', 'siamese', 256): (0, 3, 0, 1.075715324927255, 0.00786590576171875), ('./desktop/', 'resnext', 128): (0, 3, 0, 1.190271885080485, 0.5851528644561768), ('./cluster/', 'transformer', 7): (3, 5, 5, 1.5694183062446536, 0.10033607482910156), ('./cluster/', 'resnext', 128): (19, 4, 2, 1.6946130004459703, 0.4902341365814209), ('./desktop/', 'resnext', 256): (3, 3, 2, 1.2198618926493896, 1.1041593551635742), ('./cluster/', 'siamese', 128): (1, 3, 1, 1.1001174398120963, 0.014616966247558594), ('./cluster/', 'resnext', 64): (21, 4, 2, 1.6157354032349192, 0.30171942710876465), ('./cluster/', 'transformer', 9): (5, 5, 5, 1.5815184868947914, 0.5936446189880371), ('./desktop/', 'siamese', 128): (0, 3, 0, 1.0355106374611664, 0.006062746047973633), ('./desktop/', 'resnext', 64): (0, 3, 0, 1.1581370630076548, 0.321209192276001), ('./cluster/', 'transformer', 6): (0, 5, 0, 1.0141641319606927, 0.08152008056640625)}\n",
      "./desktop/\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'get_mapping_sensitivity' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-4b0d6bc1b05d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0msize\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                 \u001b[0mfinal_heads_on_cpu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_time_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mworkload\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                 \u001b[0mget_mapping_sensitivity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"siamese\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfinal_heads_on_cpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mworkload\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"resnext\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0msize\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_mapping_sensitivity' is not defined"
     ]
    }
   ],
   "source": [
    "print best_time_config\n",
    "workloads = [\"siamese\", \"transformer\" , \"resnext\"]\n",
    "home = [\"./desktop/\",\"./cluster/\"]\n",
    "HOME = \"./desktop/\"\n",
    "for h in home:\n",
    "    print h\n",
    "    HOME=h\n",
    "    for workload in workloads:\n",
    "        if workload==\"transformer\":\n",
    "            for size in [6,7,8,9]:\n",
    "                final_heads_on_cpu,_,_,_,_ = best_time_config[(h,workload,size)]\n",
    "                get_mapping_sensitivity(\"transformer\",size,16,final_heads_on_cpu)\n",
    "        if workload==\"siamese\":\n",
    "            for size in [64,128,256]:\n",
    "                final_heads_on_cpu,_,_,_,_ = best_time_config[(h,workload,size)]\n",
    "                get_mapping_sensitivity(\"siamese\",size,2,final_heads_on_cpu)\n",
    "        if workload==\"resnext\":\n",
    "            for size in [64,128,256]:\n",
    "                final_heads_on_cpu,_,_,_,_ = best_time_config[(h,workload,size)]\n",
    "                get_mapping_sensitivity(\"resnext\",size,32,final_heads_on_cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute utilization -- DEPRECATED -- DO NOT USE\n",
    "def get_utilization(size,num_queues_gpu=1,num_queues_cpu=0,num_heads_on_cpu=0,dag=\"transformer\",heft=False,heft_version=\"eager\"):\n",
    "        \n",
    "    if not heft:\n",
    "        folder=\"dumps_\"+dag+\"/\"+\"parameterised_\"+dag+\"_multiple_runs/\"\n",
    "#         print \"Operating on folder\",folder\n",
    "        filename=HOME+\"{4}/{2}_GPU{0}_CPU{1}_{3}.json\".format(num_queues_gpu,num_queues_cpu,size,num_heads_on_cpu,folder)\n",
    "#         if !path.exists(filename):\n",
    "#             print filename\n",
    "#             exit(-1)\n",
    "        \n",
    "        with open(HOME+\"{4}/{2}_GPU{0}_CPU{1}_{3}.json\".format(num_queues_gpu,num_queues_cpu,size,num_heads_on_cpu,folder)) as f:\n",
    "            timestamps = json.load(f)\n",
    "       \n",
    "  \n",
    "    else:\n",
    "        size = 2**size\n",
    "        if heft_version == \"eager\":\n",
    "            with open(\"./eager_heft/eager_siamese_128_with_delays.json\") as f:\n",
    "                timestamps = json.load(f)\n",
    "        elif heft_version == \"dynamic\":\n",
    "            with open(\"./dynamic_heft/dheft_siamese_128_with_delays.json\") as f:\n",
    "                timestamps = json.load(f)\n",
    "\n",
    "    kernels = timestamps.keys()\n",
    "    reference_device = {}\n",
    "    reference_host = {}\n",
    "    total_time = 0\n",
    "    global_reference = None\n",
    "    utilization = {'copy':[],'gpu':[],'cpu':[]} \n",
    "    for kernel in kernels:\n",
    "        device = timestamps[kernel][\"device\"]\n",
    "        if device == 'gpu':\n",
    "            t = timestamps[kernel][\"write\"][\"device_start\"]\n",
    "            copy_start = timestamps[kernel][\"write\"][\"device_start\"]\n",
    "            copy_end = timestamps[kernel][\"write\"][\"device_end\"]\n",
    "            device_start = timestamps[kernel][\"nd_range\"][\"device_start\"]\n",
    "            device_end = timestamps[kernel][\"write\"][\"device_end\"]\n",
    "            if(copy_start!=-1 and copy_end!=-1):\n",
    "                utilization['copy'].append((copy_start,copy_end))\n",
    "            utilization['gpu'].append((device_start,device_end))\n",
    "        else:\n",
    "            t = timestamps[kernel][\"nd_range\"][\"device_start\"]\n",
    "            device_start = timestamps[kernel][\"nd_range\"][\"device_start\"]\n",
    "            device_end = timestamps[kernel][\"write\"][\"device_end\"]\n",
    "            utilization['cpu'].append((device_start,device_end))\n",
    "        if t == -1:\n",
    "            continue\n",
    "        if not (device in reference_device):\n",
    "            reference_device[device] = t\n",
    "        else:\n",
    "            reference_device[device] = min(reference_device[device],t)\n",
    "\n",
    "        t = timestamps[kernel][\"write\"][\"host_queued_end\"]\n",
    "\n",
    "        if not (device in reference_host):\n",
    "            reference_host[device] = t\n",
    "        else:\n",
    "            reference_host[device] = min(reference_host[device],t)\n",
    "\n",
    "        t = timestamps[kernel][\"write\"][\"host_queued_start\"]\n",
    "        #print timestamps[kernel][\"write\"][\"host_queued_end\"]-timestamps[kernel][\"write\"][\"host_queued_start\"]\n",
    "        if not global_reference:\n",
    "            global_reference = t\n",
    "        else:\n",
    "            global_reference = min(global_reference,t)\n",
    "\n",
    "    relative_timestamps = deepcopy(timestamps)\n",
    "\n",
    "  \n",
    "\n",
    "    for kernel,kernel_timestamps in relative_timestamps.items():\n",
    "        device = kernel_timestamps[\"device\"]\n",
    "        for event_type,event_timestamps in kernel_timestamps.items():\n",
    "            #print(event_type)\n",
    "            if event_type in [\"device\",\"cmdq\"]:\n",
    "                continue\n",
    "            else:\n",
    "                #continue\n",
    "                for sub_event_type in event_timestamps:\n",
    "                    if  sub_event_type[:4] == \"host\":\n",
    "                        event_timestamps[sub_event_type] -= global_reference\n",
    "                        continue\n",
    "                    else:\n",
    "                       event_timestamps[sub_event_type] = event_timestamps[sub_event_type] - reference_device[device] + reference_host[device] - global_reference\n",
    "    #                     event_timestamps[sub_event_type] = event_timestamps[sub_event_type] - reference_device[device] + \\\n",
    "    #                     kernel_timestamps[\"write\"][\"host_queued_start\"] - global_reference\n",
    "                    total_time = max(total_time,event_timestamps[sub_event_type])\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    total_time_copy = 0\n",
    "    min_start_time = float(\"inf\")\n",
    "    max_end_time = 0.0\n",
    "    for u in utilization['copy']:\n",
    "        total_time_copy += u[1]-u[0]\n",
    "        min_start_time = min(min_start_time,u[0])\n",
    "        max_end_time = max(max_end_time,u[1])\n",
    "    actual_time_copy = max_end_time - min_start_time\n",
    "        \n",
    "    \n",
    "#     print total_time_copy,actual_time_copy\n",
    "    \n",
    "    #print \"Total Time Taken - \",total_time\n",
    "    #print(json.dumps(relative_timestamps,sort_keys=True,indent=1))          \n",
    "    return total_time,relative_timestamps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_utilization(size=64,num_queues_gpu=0,num_queues_cpu=0,num_heads_on_cpu=0,dag=\"siamese\"):\n",
    "    total_time,relative_timestamps=create_relative_timestamps(size,num_queues_gpu,num_queues_cpu,num_heads_on_cpu,dag)\n",
    "    \n",
    "    h2d_timing_information = []\n",
    "    d2h_timing_information = []\n",
    "    gpu_timing_information = []\n",
    "    cpu_timing_information = []\n",
    "    for kernel,kernel_timestamps in relative_timestamps.items():\n",
    "        \n",
    "        device = kernel_timestamps[\"device\"]\n",
    "        for event_type,event_timestamps in kernel_timestamps.items():\n",
    "            if event_type in [\"device\",\"cmdq\"]:\n",
    "                continue\n",
    "            else:\n",
    "                if device==\"gpu\":\n",
    "                    if event_type ==\"write\":\n",
    "                        if event_timestamps[\"device_start\"]>=0 and event_timestamps[\"device_end\"]>=0:\n",
    "                            h2d_timing_information.append((kernel,event_timestamps[\"device_start\"],event_timestamps[\"device_end\"]))\n",
    "    #                         print kernel,device\n",
    "    #                         print(h2d_timing_information[-1])\n",
    "                    if event_type ==\"read\":\n",
    "                        if event_timestamps[\"device_start\"]>=0 and event_timestamps[\"device_end\"]>=0:\n",
    "                            d2h_timing_information.append((kernel,event_timestamps[\"device_start\"],event_timestamps[\"device_end\"]))\n",
    "                    if event_type ==\"nd_range\":\n",
    "                        gpu_timing_information.append((kernel,event_timestamps[\"device_start\"],event_timestamps[\"device_end\"]))\n",
    "#                         print kernel,device\n",
    "#                         print gpu_timing_information[-1]\n",
    "                        #if event_timestamps[\"device_start\"]>=0 and event_timestamps[\"device_end\"]>=0:\n",
    "                         #   d2h_timing_information.append((event_timestamps[\"device_start\"],event_timestamps[\"device_end\"]))\n",
    "\n",
    "                if device==\"cpu\":\n",
    "                    if event_type ==\"nd_range\":\n",
    "                        cpu_timing_information.append((kernel,event_timestamps[\"device_start\"],event_timestamps[\"device_end\"]))\n",
    "#                         print kernel,device\n",
    "#                         print cpu_timing_information[-1]\n",
    "                        \n",
    "    return gpu_timing_information,cpu_timing_information,h2d_timing_information,d2h_timing_information\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_overlap(size=64,num_queues_gpu=0,num_queues_cpu=0,num_heads_on_cpu=0,dag=\"siamese\"):\n",
    "    gpu_timing_information,cpu_timing_information,h2d_timing_information,d2h_timing_information = get_utilization(size,num_queues_gpu,num_queues_cpu,num_heads_on_cpu,dag)\n",
    "    idle_time_cpu = 0.0\n",
    "    idle_time_gpu = 0.0\n",
    "    idle_cpu_max = 0.0\n",
    "    idle_gpu_max = 0.0\n",
    "#     print gpu_timing_information\n",
    "    gpu_timing_information.sort(key = lambda x: x[1])\n",
    "    final_cpu=None\n",
    "    final_gpu=None\n",
    "    if len(gpu_timing_information)>0:\n",
    "        final_gpu = gpu_timing_information[-1][2]\n",
    "#     print \"GPU Idleness\"\n",
    "    for idx in range(0,len(gpu_timing_information)-1):\n",
    "        idle = gpu_timing_information[idx+1][1]-gpu_timing_information[idx][2]\n",
    "        if idle>=0:\n",
    "            idle_time_gpu+=idle\n",
    "            idle_gpu_max=max(idle_gpu_max,idle)\n",
    "#             print idle\n",
    "    cpu_timing_information.sort(key = lambda x: x[1])\n",
    "    if len(cpu_timing_information)>0:\n",
    "        final_cpu = cpu_timing_information[-1][2]\n",
    "#     print \"CPU Idleness\"\n",
    "    for idx in range(0,len(cpu_timing_information)-1):\n",
    "        idle = cpu_timing_information[idx+1][1]-cpu_timing_information[idx][2]\n",
    "        if idle>=0:\n",
    "            idle_time_cpu+=idle\n",
    "#             print idle\n",
    "            idle_cpu_max=max(idle_cpu_max,idle)\n",
    "#     print \"TOTAL\"\n",
    "#     print \"CPU Idle time: \",idle_time_cpu, \"GPU Idle time: \",idle_time_gpu\n",
    "#     print \"MAX\"\n",
    "#     print \"CPU Idle time: \",idle_cpu_max, \"GPU Idle time: \",idle_gpu_max\n",
    "    return idle_time_cpu,idle_time_gpu,final_cpu,final_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "workload size ngpu ncpu speedup idle_cpu_fine, idle_gpu_fine, idle_gpu_coarse ratio\n",
      "./desktop/\n",
      "siamese 64 3 0 1.00611103888 None 0.928527607362 0.130586712683\n",
      "siamese 128 3 0 1.01738172952 None 1.25367019461 0.142132765628\n",
      "siamese 256 3 0 1.04461687682 None 1.33291956306 0.156039293188\n",
      "transformer 6 5 2 1.07062465109 0.000633024962118 0.0222397036891 0.0266399072423\n",
      "transformer 7 5 2 1.12411210754 0.000985141429851 0.026052532032 0.0377218318892\n",
      "transformer 8 5 2 1.20760711737 0.00198739289879 0.00720340596906 0.0750496390882\n",
      "transformer 9 5 2 1.13498464559 0.000354875614078 0.00468862042042 0.0486084972261\n",
      "resnext 64 0 3 0 1.1650541214 None 0.595045896841 0.655008398135\n",
      "resnext 128 0 3 0 1.18860909527 None 0.620571295978 0.695352483269\n",
      "DEBUG 0.935622215271 0.642241001129 1.32172656059 0.000171422958374\n",
      "resnext 256 3 3 2 1.19704330214 0.000278309473167 0.623489797118 0.723851466984\n",
      "./cluster/\n",
      "siamese 64 3 0 1.01612620508 None 1.11912128713 0.0693682635879\n",
      "siamese 128 3 1 1.00466497031 0.0 10.6181818182 0.104397568824\n",
      "siamese 256 3 1 1.08065995814 0.0 3.41709621993 0.105599214145\n",
      "transformer 6 5 0 1.54207124474 None 0.0230886689132 0.0362078318166\n",
      "transformer 7 5 5 1.13901720369 0.00603079555175 0.0253572440817 0.0267667874013\n",
      "transformer 8 5 5 1.56338361097 0.00868435826318 0.0631771021196 0.0575140762827\n",
      "transformer 9 5 5 1.56507020691 0.00256336396208 0.0556553863855 0.0567848102955\n",
      "DEBUG 0.25586605072 0.187289714813 0.460395812988 0.00640916824341\n",
      "resnext 64 16 4 2 1.65597437624 0.0237794058068 0.688228924276 0.564586429577\n",
      "DEBUG 0.478932619095 0.280017614365 0.794471502304 0.00497579574585\n",
      "resnext 128 15 4 2 1.78728485971 0.0124098841427 0.648325722017 0.61382013456\n",
      "DEBUG 0.934443473816 0.49223279953 1.49891448021 0.00267243385315\n",
      "resnext 256 14 3 2 1.85275812366 0.00404778473253 0.629073711877 0.634943315286\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style>  \n",
       "<table id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72\" > \n",
       "<thead>    <tr> \n",
       "        <th class=\"blank level0\" ></th> \n",
       "        <th class=\"col_heading level0 col0\" >platform</th> \n",
       "        <th class=\"col_heading level0 col1\" >workload</th> \n",
       "        <th class=\"col_heading level0 col2\" >size</th> \n",
       "        <th class=\"col_heading level0 col3\" >ngpu</th> \n",
       "        <th class=\"col_heading level0 col4\" >ncpu</th> \n",
       "        <th class=\"col_heading level0 col5\" >speedup</th> \n",
       "        <th class=\"col_heading level0 col6\" >idle_ratio</th> \n",
       "        <th class=\"col_heading level0 col7\" >idle_ratio_gpu</th> \n",
       "        <th class=\"col_heading level0 col8\" >idle_ratio_cpu</th> \n",
       "    </tr></thead> \n",
       "<tbody>    <tr> \n",
       "        <th id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72level0_row0\" class=\"row_heading level0 row0\" >0</th> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row0_col0\" class=\"data row0 col0\" >./desktop/</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row0_col1\" class=\"data row0 col1\" >siamese</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row0_col2\" class=\"data row0 col2\" >64</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row0_col3\" class=\"data row0 col3\" >3</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row0_col4\" class=\"data row0 col4\" >0</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row0_col5\" class=\"data row0 col5\" >1.00611</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row0_col6\" class=\"data row0 col6\" >0.928528</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row0_col7\" class=\"data row0 col7\" >0.928528</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row0_col8\" class=\"data row0 col8\" >nan</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72level0_row1\" class=\"row_heading level0 row1\" >1</th> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row1_col0\" class=\"data row1 col0\" >./desktop/</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row1_col1\" class=\"data row1 col1\" >siamese</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row1_col2\" class=\"data row1 col2\" >128</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row1_col3\" class=\"data row1 col3\" >3</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row1_col4\" class=\"data row1 col4\" >0</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row1_col5\" class=\"data row1 col5\" >1.01738</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row1_col6\" class=\"data row1 col6\" >1.25367</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row1_col7\" class=\"data row1 col7\" >1.25367</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row1_col8\" class=\"data row1 col8\" >nan</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72level0_row2\" class=\"row_heading level0 row2\" >2</th> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row2_col0\" class=\"data row2 col0\" >./desktop/</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row2_col1\" class=\"data row2 col1\" >siamese</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row2_col2\" class=\"data row2 col2\" >256</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row2_col3\" class=\"data row2 col3\" >3</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row2_col4\" class=\"data row2 col4\" >0</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row2_col5\" class=\"data row2 col5\" >1.04462</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row2_col6\" class=\"data row2 col6\" >1.33292</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row2_col7\" class=\"data row2 col7\" >1.33292</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row2_col8\" class=\"data row2 col8\" >nan</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72level0_row3\" class=\"row_heading level0 row3\" >3</th> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row3_col0\" class=\"data row3 col0\" >./desktop/</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row3_col1\" class=\"data row3 col1\" >transformer</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row3_col2\" class=\"data row3 col2\" >6</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row3_col3\" class=\"data row3 col3\" >5</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row3_col4\" class=\"data row3 col4\" >2</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row3_col5\" class=\"data row3 col5\" >1.07062</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row3_col6\" class=\"data row3 col6\" >52.5283</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row3_col7\" class=\"data row3 col7\" >1.40531</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row3_col8\" class=\"data row3 col8\" >45.0472</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72level0_row4\" class=\"row_heading level0 row4\" >4</th> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row4_col0\" class=\"data row4 col0\" >./desktop/</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row4_col1\" class=\"data row4 col1\" >transformer</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row4_col2\" class=\"data row4 col2\" >7</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row4_col3\" class=\"data row4 col3\" >5</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row4_col4\" class=\"data row4 col4\" >2</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row4_col5\" class=\"data row4 col5\" >1.12411</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row4_col6\" class=\"data row4 col6\" >43.2086</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row4_col7\" class=\"data row4 col7\" >1.6278</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row4_col8\" class=\"data row4 col8\" >44.5787</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72level0_row5\" class=\"row_heading level0 row5\" >5</th> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row5_col0\" class=\"data row5 col0\" >./desktop/</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row5_col1\" class=\"data row5 col1\" >transformer</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row5_col2\" class=\"data row5 col2\" >8</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row5_col3\" class=\"data row5 col3\" >5</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row5_col4\" class=\"data row5 col4\" >2</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row5_col5\" class=\"data row5 col5\" >1.20761</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row5_col6\" class=\"data row5 col6\" >141.895</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row5_col7\" class=\"data row5 col7\" >12.5818</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row5_col8\" class=\"data row5 col8\" >46.54</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72level0_row6\" class=\"row_heading level0 row6\" >6</th> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row6_col0\" class=\"data row6 col0\" >./desktop/</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row6_col1\" class=\"data row6 col1\" >transformer</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row6_col2\" class=\"data row6 col2\" >9</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row6_col3\" class=\"data row6 col3\" >5</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row6_col4\" class=\"data row6 col4\" >2</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row6_col5\" class=\"data row6 col5\" >1.13498</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row6_col6\" class=\"data row6 col6\" >237.895</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row6_col7\" class=\"data row6 col7\" >11.767</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row6_col8\" class=\"data row6 col8\" >175.181</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72level0_row7\" class=\"row_heading level0 row7\" >7</th> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row7_col0\" class=\"data row7 col0\" >./desktop/</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row7_col1\" class=\"data row7 col1\" >resnext</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row7_col2\" class=\"data row7 col2\" >64</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row7_col3\" class=\"data row7 col3\" >3</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row7_col4\" class=\"data row7 col4\" >0</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row7_col5\" class=\"data row7 col5\" >1.16505</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row7_col6\" class=\"data row7 col6\" >1.34256</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row7_col7\" class=\"data row7 col7\" >1.34256</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row7_col8\" class=\"data row7 col8\" >nan</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72level0_row8\" class=\"row_heading level0 row8\" >8</th> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row8_col0\" class=\"data row8 col0\" >./desktop/</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row8_col1\" class=\"data row8 col1\" >resnext</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row8_col2\" class=\"data row8 col2\" >128</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row8_col3\" class=\"data row8 col3\" >3</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row8_col4\" class=\"data row8 col4\" >0</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row8_col5\" class=\"data row8 col5\" >1.18861</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row8_col6\" class=\"data row8 col6\" >1.40148</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row8_col7\" class=\"data row8 col7\" >1.40148</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row8_col8\" class=\"data row8 col8\" >nan</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72level0_row9\" class=\"row_heading level0 row9\" >9</th> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row9_col0\" class=\"data row9 col0\" >./desktop/</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row9_col1\" class=\"data row9 col1\" >resnext</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row9_col2\" class=\"data row9 col2\" >256</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row9_col3\" class=\"data row9 col3\" >3</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row9_col4\" class=\"data row9 col4\" >2</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row9_col5\" class=\"data row9 col5\" >1.19704</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row9_col6\" class=\"data row9 col6\" >3.51386</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row9_col7\" class=\"data row9 col7\" >1.45681</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row9_col8\" class=\"data row9 col8\" >7710.32</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72level0_row10\" class=\"row_heading level0 row10\" >10</th> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row10_col0\" class=\"data row10 col0\" >./cluster/</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row10_col1\" class=\"data row10 col1\" >siamese</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row10_col2\" class=\"data row10 col2\" >64</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row10_col3\" class=\"data row10 col3\" >3</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row10_col4\" class=\"data row10 col4\" >0</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row10_col5\" class=\"data row10 col5\" >1.01613</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row10_col6\" class=\"data row10 col6\" >1.11912</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row10_col7\" class=\"data row10 col7\" >1.11912</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row10_col8\" class=\"data row10 col8\" >nan</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72level0_row11\" class=\"row_heading level0 row11\" >11</th> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row11_col0\" class=\"data row11 col0\" >./cluster/</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row11_col1\" class=\"data row11 col1\" >siamese</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row11_col2\" class=\"data row11 col2\" >128</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row11_col3\" class=\"data row11 col3\" >3</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row11_col4\" class=\"data row11 col4\" >1</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row11_col5\" class=\"data row11 col5\" >1.00466</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row11_col6\" class=\"data row11 col6\" >17.5304</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row11_col7\" class=\"data row11 col7\" >10.6182</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row11_col8\" class=\"data row11 col8\" >18.8073</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72level0_row12\" class=\"row_heading level0 row12\" >12</th> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row12_col0\" class=\"data row12 col0\" >./cluster/</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row12_col1\" class=\"data row12 col1\" >siamese</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row12_col2\" class=\"data row12 col2\" >256</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row12_col3\" class=\"data row12 col3\" >3</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row12_col4\" class=\"data row12 col4\" >1</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row12_col5\" class=\"data row12 col5\" >1.08066</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row12_col6\" class=\"data row12 col6\" >23.7177</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row12_col7\" class=\"data row12 col7\" >3.4171</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row12_col8\" class=\"data row12 col8\" >63.5658</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72level0_row13\" class=\"row_heading level0 row13\" >13</th> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row13_col0\" class=\"data row13 col0\" >./cluster/</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row13_col1\" class=\"data row13 col1\" >transformer</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row13_col2\" class=\"data row13 col2\" >6</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row13_col3\" class=\"data row13 col3\" >5</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row13_col4\" class=\"data row13 col4\" >0</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row13_col5\" class=\"data row13 col5\" >1.54207</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row13_col6\" class=\"data row13 col6\" >2.4186</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row13_col7\" class=\"data row13 col7\" >2.4186</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row13_col8\" class=\"data row13 col8\" >nan</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72level0_row14\" class=\"row_heading level0 row14\" >14</th> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row14_col0\" class=\"data row14 col0\" >./cluster/</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row14_col1\" class=\"data row14 col1\" >transformer</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row14_col2\" class=\"data row14 col2\" >7</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row14_col3\" class=\"data row14 col3\" >5</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row14_col4\" class=\"data row14 col4\" >5</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row14_col5\" class=\"data row14 col5\" >1.13902</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row14_col6\" class=\"data row14 col6\" >41.8764</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row14_col7\" class=\"data row14 col7\" >1.39219</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row14_col8\" class=\"data row14 col8\" >5.05477</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72level0_row15\" class=\"row_heading level0 row15\" >15</th> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row15_col0\" class=\"data row15 col0\" >./cluster/</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row15_col1\" class=\"data row15 col1\" >transformer</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row15_col2\" class=\"data row15 col2\" >8</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row15_col3\" class=\"data row15 col3\" >5</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row15_col4\" class=\"data row15 col4\" >5</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row15_col5\" class=\"data row15 col5\" >1.56338</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row15_col6\" class=\"data row15 col6\" >25.026</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row15_col7\" class=\"data row15 col7\" >1.56683</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row15_col8\" class=\"data row15 col8\" >10.3522</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72level0_row16\" class=\"row_heading level0 row16\" >16</th> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row16_col0\" class=\"data row16 col0\" >./cluster/</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row16_col1\" class=\"data row16 col1\" >transformer</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row16_col2\" class=\"data row16 col2\" >9</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row16_col3\" class=\"data row16 col3\" >5</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row16_col4\" class=\"data row16 col4\" >5</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row16_col5\" class=\"data row16 col5\" >1.56507</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row16_col6\" class=\"data row16 col6\" >28.4258</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row16_col7\" class=\"data row16 col7\" >1.59701</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row16_col8\" class=\"data row16 col8\" >34.9189</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72level0_row17\" class=\"row_heading level0 row17\" >17</th> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row17_col0\" class=\"data row17 col0\" >./cluster/</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row17_col1\" class=\"data row17 col1\" >resnext</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row17_col2\" class=\"data row17 col2\" >64</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row17_col3\" class=\"data row17 col3\" >4</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row17_col4\" class=\"data row17 col4\" >2</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row17_col5\" class=\"data row17 col5\" >1.65597</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row17_col6\" class=\"data row17 col6\" >3.69781</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row17_col7\" class=\"data row17 col7\" >1.36615</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row17_col8\" class=\"data row17 col8\" >71.8339</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72level0_row18\" class=\"row_heading level0 row18\" >18</th> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row18_col0\" class=\"data row18 col0\" >./cluster/</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row18_col1\" class=\"data row18 col1\" >resnext</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row18_col2\" class=\"data row18 col2\" >128</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row18_col3\" class=\"data row18 col3\" >4</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row18_col4\" class=\"data row18 col4\" >2</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row18_col5\" class=\"data row18 col5\" >1.78728</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row18_col6\" class=\"data row18 col6\" >4.46819</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row18_col7\" class=\"data row18 col7\" >1.71037</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row18_col8\" class=\"data row18 col8\" >159.667</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72level0_row19\" class=\"row_heading level0 row19\" >19</th> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row19_col0\" class=\"data row19 col0\" >./cluster/</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row19_col1\" class=\"data row19 col1\" >resnext</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row19_col2\" class=\"data row19 col2\" >256</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row19_col3\" class=\"data row19 col3\" >3</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row19_col4\" class=\"data row19 col4\" >2</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row19_col5\" class=\"data row19 col5\" >1.85276</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row19_col6\" class=\"data row19 col6\" >4.91682</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row19_col7\" class=\"data row19 col7\" >1.89838</td> \n",
       "        <td id=\"T_8500a7f0_0a53_11ec_85e2_9848273b8d72row19_col8\" class=\"data row19 col8\" >560.88</td> \n",
       "    </tr></tbody> \n",
       "</table> "
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fa19eabc750>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.max_columns=None\n",
    "workloads = [\"siamese\", \"transformer\" , \"resnext\"]\n",
    "home = [\"./desktop/\",\"./cluster/\"]\n",
    "HOME = \"./desktop/\"\n",
    "print \"workload size ngpu ncpu speedup idle_cpu_fine, idle_gpu_fine, idle_gpu_coarse ratio\"\n",
    "results = {\"platform\" :[], \"workload\":[], \"size\":[] ,\"ngpu\": [], \"ncpu\" :[], \"speedup\":[], \"idle_cpu_c\":[],\"idle_cpu_f\":[], \"idle_gpu_c\":[], \"idle_gpu_f\": [], \"idle_ratio\":[],\"idle_ratio_cpu\":[],\"idle_ratio_gpu\":[]}\n",
    "for h in home:\n",
    "    print h\n",
    "    HOME=h\n",
    "    for workload in workloads:\n",
    "        \n",
    "        if workload==\"transformer\":\n",
    "            for size in [6,7,8,9]:\n",
    "                final_heads_on_cpu,ng,nc,sp,best_time,default_time = best_time_config[(h,workload,size)]\n",
    "#                 st=get_mapping_sensitivity(\"transformer\",size,16,final_heads_on_cpu)\n",
    "                c1,g1,fc1,fg1=compute_overlap(size,num_queues_gpu=ng,num_queues_cpu=nc,num_heads_on_cpu=final_heads_on_cpu,dag=\"transformer\")\n",
    "                c2,g2,fc2,fg2=compute_overlap(size,num_queues_gpu=1,num_queues_cpu=1,num_heads_on_cpu=final_heads_on_cpu,dag=\"transformer\")\n",
    "                results[\"platform\"].append(h)\n",
    "                results[\"workload\"].append(workload)\n",
    "                results[\"size\"].append(size)\n",
    "                results[\"ngpu\"].append(ng)\n",
    "                results[\"ncpu\"].append(nc)\n",
    "                results[\"speedup\"].append(sp)\n",
    "                results[\"idle_cpu_c\"].append(c2)\n",
    "                results[\"idle_cpu_f\"].append(c1)\n",
    "                results[\"idle_gpu_c\"].append(g2)\n",
    "                results[\"idle_gpu_f\"].append(g1)\n",
    "                if final_heads_on_cpu == 0:\n",
    "                    results[\"idle_ratio\"].append(g2/g1)\n",
    "                else:\n",
    "                    results[\"idle_ratio\"].append((g2+default_time)/(g1+c1))\n",
    "                results[\"idle_ratio_gpu\"].append((g2)/(g1))\n",
    "                if final_heads_on_cpu > 0:\n",
    "                    results[\"idle_ratio_cpu\"].append(g2/(c1))\n",
    "                else:\n",
    "                    results[\"idle_ratio_cpu\"].append(None)\n",
    "                    \n",
    "#                 results[\"mapping_sensitivity\"].append(st)\n",
    "                cpu_idle_ratio = None\n",
    "                gpu_idle_ratio= None\n",
    "                if(c1!=0 or fc1!=None):\n",
    "                    cpu_idle_ratio=c1/fc1\n",
    "                if(g1!=0 or g2!=None):\n",
    "                    gpu_idle_ratio=g1/fg1\n",
    "                \n",
    "                print workload,size,ng,nc,sp,cpu_idle_ratio,gpu_idle_ratio,g2/fg2\n",
    "\n",
    "        if workload==\"siamese\":\n",
    "            for size in [64,128,256]:\n",
    "                final_heads_on_cpu,ng,nc,sp,best_time,default_time = best_time_config[(h,workload,size)]\n",
    "#                 st=get_mapping_sensitivity(\"siamese\",size,2,final_heads_on_cpu)\n",
    "                c1,g1,fc1,fg1=compute_overlap(size,num_queues_gpu=ng,num_queues_cpu=nc,num_heads_on_cpu=final_heads_on_cpu,dag=\"siamese\")\n",
    "                c2,g2,fc2,fg2=compute_overlap(size,num_queues_gpu=1,num_queues_cpu=1,num_heads_on_cpu=final_heads_on_cpu,dag=\"siamese\")\n",
    "                results[\"platform\"].append(h)\n",
    "                results[\"workload\"].append(workload)\n",
    "                results[\"size\"].append(size)\n",
    "                results[\"ngpu\"].append(ng)\n",
    "                results[\"ncpu\"].append(nc)\n",
    "                results[\"speedup\"].append(sp)\n",
    "                results[\"idle_cpu_c\"].append(c2)\n",
    "                results[\"idle_cpu_f\"].append(c1)\n",
    "                results[\"idle_gpu_c\"].append(g2)\n",
    "                results[\"idle_gpu_f\"].append(g1)\n",
    "                if final_heads_on_cpu == 0:\n",
    "                    results[\"idle_ratio\"].append(g2/g1)\n",
    "                else:\n",
    "                    results[\"idle_ratio\"].append((g2+default_time)/(g1+c1))\n",
    "                results[\"idle_ratio_gpu\"].append((g2)/(g1))\n",
    "                if final_heads_on_cpu > 0:\n",
    "                    results[\"idle_ratio_cpu\"].append(default_time/(c1))\n",
    "                else:\n",
    "                    results[\"idle_ratio_cpu\"].append(None)\n",
    "#                 results[\"mapping_sensitivity\"].append(st)\n",
    "                cpu_idle_ratio = None\n",
    "                gpu_idle_ratio= None\n",
    "                if(c1!=0 or fc1!=None):\n",
    "                    cpu_idle_ratio=c2/c1\n",
    "                if(g1!=0 or g2!=None):\n",
    "                    gpu_idle_ratio=g2/g1\n",
    "                print workload,size,ng,nc,sp,cpu_idle_ratio,gpu_idle_ratio,g2/fg2\n",
    "                \n",
    "        if workload==\"resnext\":\n",
    "            for size in [64,128,256]:\n",
    "                final_heads_on_cpu,ng,nc,sp,best_time,default_time = best_time_config[(h,workload,size)]\n",
    "                \n",
    "#                 st=get_mapping_sensitivity(\"resnext\",size,32,final_heads_on_cpu)\n",
    "                c1,g1,fc1,fg1=compute_overlap(size,num_queues_gpu=ng,num_queues_cpu=nc,num_heads_on_cpu=final_heads_on_cpu,dag=\"resnext\")\n",
    "                c2,g2,fc2,fg2=compute_overlap(size,num_queues_gpu=1,num_queues_cpu=1,num_heads_on_cpu=final_heads_on_cpu,dag=\"resnext\")\n",
    "                results[\"platform\"].append(h)\n",
    "                results[\"workload\"].append(workload)\n",
    "                results[\"size\"].append(size)\n",
    "                results[\"ngpu\"].append(ng)\n",
    "                results[\"ncpu\"].append(nc)\n",
    "                results[\"speedup\"].append(sp)\n",
    "                results[\"idle_cpu_c\"].append(c2)\n",
    "                results[\"idle_cpu_f\"].append(c1)\n",
    "                results[\"idle_gpu_c\"].append(g2)\n",
    "                results[\"idle_gpu_f\"].append(g1)\n",
    "                if final_heads_on_cpu == 0:\n",
    "                    results[\"idle_ratio\"].append(g2/g1)\n",
    "                else:\n",
    "                    results[\"idle_ratio\"].append((g2+default_time)/(g1+c1))\n",
    "                    print \"DEBUG\",g2,g1,default_time,c1\n",
    "                results[\"idle_ratio_gpu\"].append((g2)/(g1))\n",
    "                if final_heads_on_cpu > 0:\n",
    "                    results[\"idle_ratio_cpu\"].append(default_time/(c1))\n",
    "                else:\n",
    "                    results[\"idle_ratio_cpu\"].append(None)\n",
    "#                 results[\"mapping_sensitivity\"].append(st)\n",
    "                cpu_idle_ratio = None\n",
    "                gpu_idle_ratio= None\n",
    "                if(c1!=0 or fc1!=None):\n",
    "                    cpu_idle_ratio=c1/fc1\n",
    "                if(g1!=0 or g2!=None):\n",
    "                    gpu_idle_ratio=g1/fg1\n",
    "                     \n",
    "                print workload,size,final_heads_on_cpu,ng,nc,sp,cpu_idle_ratio,gpu_idle_ratio,g2/fg2\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "df = df[[\"platform\",\"workload\", \"size\", \"ngpu\", \"ncpu\", \"speedup\", \"idle_ratio\",\"idle_ratio_gpu\",\"idle_ratio_cpu\" ]]\n",
    "df.style\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./desktop/\n",
      "Opening ./desktop/coarse_experiments/eager_siamese_64_with_delays.json\n",
      "Opening  ./desktop/coarse_experiments/dheft_siamese_64_with_delays.json\n",
      "Opening ./desktop/coarse_experiments/eager_siamese_128_with_delays.json\n",
      "Opening  ./desktop/coarse_experiments/dheft_siamese_128_with_delays.json\n",
      "Opening ./desktop/coarse_experiments/eager_siamese_256_with_delays.json\n",
      "Opening  ./desktop/coarse_experiments/dheft_siamese_256_with_delays.json\n",
      "Opening ./desktop/coarse_experiments/eager_transformer_64_with_delays.json\n",
      "Opening  ./desktop/coarse_experiments/dheft_transformer_64_with_delays.json\n",
      "Opening ./desktop/coarse_experiments/eager_transformer_128_with_delays.json\n",
      "Opening  ./desktop/coarse_experiments/dheft_transformer_128_with_delays.json\n",
      "Opening ./desktop/coarse_experiments/eager_transformer_256_with_delays.json\n",
      "Opening  ./desktop/coarse_experiments/dheft_transformer_256_with_delays.json\n",
      "Opening ./desktop/coarse_experiments/eager_resnext_64_with_delays.json\n",
      "Opening  ./desktop/coarse_experiments/dheft_resnext_64_with_delays.json\n",
      "Opening ./desktop/coarse_experiments/eager_resnext_128_with_delays.json\n",
      "Opening  ./desktop/coarse_experiments/dheft_resnext_128_with_delays.json\n",
      "Opening ./desktop/coarse_experiments/eager_resnext_256_with_delays.json\n",
      "Opening  ./desktop/coarse_experiments/dheft_resnext_256_with_delays.json\n",
      "./cluster/\n",
      "Opening ./cluster/coarse_experiments/eager_siamese_64_with_delays.json\n",
      "Opening  ./cluster/coarse_experiments/dheft_siamese_64_with_delays.json\n",
      "Opening ./cluster/coarse_experiments/eager_siamese_128_with_delays.json\n",
      "Opening  ./cluster/coarse_experiments/dheft_siamese_128_with_delays.json\n",
      "Opening ./cluster/coarse_experiments/eager_siamese_256_with_delays.json\n",
      "Opening  ./cluster/coarse_experiments/dheft_siamese_256_with_delays.json\n",
      "Opening ./cluster/coarse_experiments/eager_transformer_64_with_delays.json\n",
      "Opening  ./cluster/coarse_experiments/dheft_transformer_64_with_delays.json\n",
      "Opening ./cluster/coarse_experiments/eager_transformer_128_with_delays.json\n",
      "Opening  ./cluster/coarse_experiments/dheft_transformer_128_with_delays.json\n",
      "Opening ./cluster/coarse_experiments/eager_transformer_256_with_delays.json\n",
      "Opening  ./cluster/coarse_experiments/dheft_transformer_256_with_delays.json\n",
      "Opening ./cluster/coarse_experiments/eager_resnext_64_with_delays.json\n",
      "Opening  ./cluster/coarse_experiments/dheft_resnext_64_with_delays.json\n",
      "Opening ./cluster/coarse_experiments/eager_resnext_128_with_delays.json\n",
      "Opening  ./cluster/coarse_experiments/dheft_resnext_128_with_delays.json\n",
      "Opening ./cluster/coarse_experiments/eager_resnext_256_with_delays.json\n",
      "Opening  ./cluster/coarse_experiments/dheft_resnext_256_with_delays.json\n"
     ]
    }
   ],
   "source": [
    "#Coarse Grained vs Fine Grained\n",
    "coarse_vs_fine_results = {}\n",
    "for h in home:\n",
    "    print h\n",
    "    HOME=h\n",
    "    for workload in workloads:\n",
    "        if workload==\"transformer\":\n",
    "            for size in [6,7,8]:\n",
    "                _,_,_,_,best_time,_ = best_time_config[(h,workload,size)]\n",
    "                eager_time,_=create_relative_timestamps(size,dag=workload,heft=True,heft_version=\"eager\")\n",
    "                dheft_time,_=create_relative_timestamps(size,dag=workload,heft=True,heft_version=\"dynamic\")\n",
    "                coarse_vs_fine_results[(h,workload,size)]=best_time,eager_time,dheft_time\n",
    "                \n",
    "        if workload==\"siamese\":\n",
    "            for size in [64,128,256]:\n",
    "                _,_,_,_,best_time,_ = best_time_config[(h,workload,size)]\n",
    "                eager_time,_=create_relative_timestamps(size,dag=workload,heft=True,heft_version=\"eager\")\n",
    "                dheft_time,_=create_relative_timestamps(size,dag=workload,heft=True,heft_version=\"dynamic\")\n",
    "                coarse_vs_fine_results[(h,workload,size)]=best_time,eager_time,dheft_time\n",
    "        if workload==\"resnext\":\n",
    "            workload_coarse=\"resnext\"\n",
    "            for size in [64,128,256]:\n",
    "                _,_,_,_,best_time,_ = best_time_config[(h,workload,size)]\n",
    "                eager_time,_=create_relative_timestamps(size,dag=workload_coarse,heft=True,heft_version=\"eager\")\n",
    "                dheft_time,_=create_relative_timestamps(size,dag=workload_coarse,heft=True,heft_version=\"dynamic\")\n",
    "                coarse_vs_fine_results[(h,workload,size)]=best_time,eager_time,dheft_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "siamese 64 0.00550103187561 0.0150547027588 0.0200529098511\n",
      "siamese 128 0.00606274604797 0.0241839885712 0.0186107158661\n",
      "siamese 256 0.00786590576172 0.036737203598 0.0339987277985\n",
      "transformer 6 0.0478324890137 0.107419013977 0.104646444321\n",
      "transformer 7 0.0636732578278 0.163958072662 0.133768081665\n",
      "transformer 8 0.144001722336 0.388954162598 0.262097597122\n",
      "resnext 64 0.321209192276 2.71548080444 2.09184718132\n",
      "resnext 128 0.585152864456 5.24205851555 4.14674925804\n",
      "resnext 256 1.10415935516 10.3810093403 8.24170851707\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for key in coarse_vs_fine_results:\n",
    "#     h,workload,size=key\n",
    "#     best_time,eager_time,dheft_time=coarse_vs_fine_results[key]\n",
    "#     print h,workload,size,eager_time/best_time,dheft_time/best_time\n",
    "\n",
    "eager_speedups = []\n",
    "dheft_speedups = []\n",
    "h=\"./desktop/\"\n",
    "HOME=h\n",
    "for workload in workloads:\n",
    "    if workload==\"transformer\":\n",
    "        for size in [6,7,8]:\n",
    "            best_time,eager_time,dheft_time=coarse_vs_fine_results[(h,workload,size)]\n",
    "            eager_speedups.append(eager_time/best_time)\n",
    "            dheft_speedups.append(dheft_time/best_time)\n",
    "            print workload,size, best_time,eager_time,dheft_time\n",
    "\n",
    "                \n",
    "    if workload==\"siamese\":\n",
    "        for size in [64,128,256]:\n",
    "            best_time,eager_time,dheft_time=coarse_vs_fine_results[(h,workload,size)]\n",
    "            eager_speedups.append(eager_time/best_time)\n",
    "            dheft_speedups.append(dheft_time/best_time)\n",
    "            print workload,size, best_time,eager_time,dheft_time\n",
    "\n",
    "                \n",
    "    if workload==\"resnext\":\n",
    "        for size in [64,128,256]:\n",
    "            best_time,eager_time,dheft_time=coarse_vs_fine_results[(h,workload,size)]\n",
    "            eager_speedups.append(eager_time/best_time)\n",
    "            dheft_speedups.append(dheft_time/best_time)\n",
    "            print workload,size, best_time,eager_time,dheft_time\n",
    "\n",
    "            \n",
    "N=len(eager_speedups)\n",
    "ind = np.arange(N) \n",
    "width = 0.35    \n",
    "\n",
    "plt.bar(ind, eager_speedups, width, label='Eager vs Clustering')\n",
    "plt.bar(ind + width, dheft_speedups, width,label='HEFT vs Clustering')\n",
    "ax = plt.gca()\n",
    "ax.yaxis.tick_right()\n",
    "# ax.yaxis.set_label_position(\"right\")\n",
    "# plt.ylabel('Speedup')\n",
    "# plt.xticks(ind + width / 2, ('G1', 'G2', 'G3', 'G4', 'G5'))\n",
    "plt.legend(loc='best')\n",
    "\n",
    "plt.savefig('desktop_bar.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-98-53933f99b865>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mworkload_revised\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"resnext\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msize\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbest_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_time_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mworkload\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0meager_time\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_relative_timestamps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkload_revised\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mheft\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mheft_version\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"eager\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mdheft_time\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_relative_timestamps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkload_revised\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mheft\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mheft_version\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"dynamic\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack"
     ]
    }
   ],
   "source": [
    "#coarse experiments for aggregated resnext\n",
    "h=\"./desktop/\"\n",
    "workload=\"resnext\"\n",
    "workload_revised=\"resnext\"\n",
    "for size in [64,128,256]:\n",
    "    _,_,_,_,best_time = best_time_config[(h,workload,size)]\n",
    "    eager_time,_=create_relative_timestamps(size,dag=workload_revised,heft=True,heft_version=\"eager\")\n",
    "    dheft_time,_=create_relative_timestamps(size,dag=workload_revised,heft=True,heft_version=\"dynamic\")\n",
    "    coarse_vs_fine_results[(h,workload,size)]=best_time,eager_time,dheft_time\n",
    "    print size,best_time,eager_time,dheft_time\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "siamese 64 0.012241601944 0.0613629817963 0.0726344585419\n",
      "siamese 128 0.0146169662476 0.0653293132782 0.0652446746826\n",
      "siamese 256 0.0166325569153 0.0625660419464 0.0629081726074\n",
      "transformer 6 0.0815200805664 1.19505882263 1.10978055\n",
      "transformer 7 0.100336074829 1.1784555912 1.05452227592\n",
      "transformer 8 0.185587644577 1.04093980789 1.01703810692\n",
      "resnext 64 0.278021097183 0.446012973785 0.511233568192\n",
      "resnext 128 0.444513082504 0.672655105591 0.9064245224\n",
      "resnext 256 0.809017896652 1.2496805191 1.50610661507\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.ticker import MaxNLocator\n",
    "eager_speedups = []\n",
    "dheft_speedups = []\n",
    "h=\"./cluster/\"\n",
    "HOME=h\n",
    "for workload in workloads:\n",
    "    if workload==\"transformer\":\n",
    "        for size in [6,7,8]:\n",
    "            best_time,eager_time,dheft_time=coarse_vs_fine_results[(h,workload,size)]\n",
    "            eager_speedups.append(eager_time/best_time)\n",
    "            dheft_speedups.append(dheft_time/best_time)\n",
    "            print workload,size, best_time,eager_time,dheft_time\n",
    "\n",
    "                \n",
    "    if workload==\"siamese\":\n",
    "        for size in [64,128,256]:\n",
    "            best_time,eager_time,dheft_time=coarse_vs_fine_results[(h,workload,size)]\n",
    "            eager_speedups.append(eager_time/best_time)\n",
    "            dheft_speedups.append(dheft_time/best_time)\n",
    "            print workload,size, best_time,eager_time,dheft_time\n",
    "\n",
    "                \n",
    "    if workload==\"resnext\":\n",
    "        for size in [64,128,256]:\n",
    "            best_time,eager_time,dheft_time=coarse_vs_fine_results[(h,workload,size)]\n",
    "            eager_speedups.append(eager_time/best_time)\n",
    "            dheft_speedups.append(dheft_time/best_time)\n",
    "            print workload,size, best_time,eager_time,dheft_time\n",
    "\n",
    "            \n",
    "N=len(eager_speedups)\n",
    "ind = np.arange(N) \n",
    "width = 0.35       \n",
    "plt.bar(ind, eager_speedups, width, label='Eager vs Clustering')\n",
    "plt.bar(ind + width, dheft_speedups, width,label='HEFT vs Clustering')\n",
    "ax = plt.gca()\n",
    "ax.yaxis.tick_left()\n",
    "ax.yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "plt.ylabel('Speedup')\n",
    "# plt.xticks(ind + width / 2, ('G1', 'G2', 'G3', 'G4', 'G5'))\n",
    "# plt.legend(loc='best')\n",
    "plt.savefig('cluster_bar.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#debug resnext\n",
    "HOME=\"./cluster/\"\n",
    "dag=\"resnext\"\n",
    "folder=\"dumps_\"+dag+\"/\"+\"parameterised_\"+dag+\"_multiple_runs/\"\n",
    "\n",
    "for size in [64,128,256]:\n",
    "    for num_queues_gpu in range(1,6):\n",
    "        for num_queues_cpu in range(1,6):\n",
    "            for num_heads_on_cpu in range(0,32):\n",
    "                filename=HOME+\"{4}/{2}_GPU{0}_CPU{1}_{3}.json\".format(num_queues_gpu,num_queues_cpu,size,num_heads_on_cpu,folder)\n",
    "                dump_filename=\"./profiling/\"+\"{4}/{2}_GPU{0}_CPU{1}_{3}.json\".format(num_queues_gpu,num_queues_cpu,size,num_heads_on_cpu,folder)    \n",
    "                if not path.exists(filename):\n",
    "                    create_command =\"python scheduling/create_resnext.py {} {} {}\".format(size,num_heads_on_cpu,32)\n",
    "                    command_header =\"python scheduling/multiple_dag_devices.py -f ./dag_info/dag_resnext/ -ng {} -nc {} -rc -fdp \\'{}\\'\".format(num_queues_cpu,num_queues_gpu,dump_filename)\n",
    "                    copy_command = \"scp anirban@10.5.30.11:~/ResearchTools/pyschedcl-anirban/pyschedcl-stable/pyschedcl/\"+dump_filename[2:]\n",
    "#                     print create_command\n",
    "#                     print command_header\n",
    "                    print copy_command\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coarse experiments with resnext\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0194914340973 0.0239727497101\n",
      "2.93431678691 3.60895158106\n"
     ]
    }
   ],
   "source": [
    "dheft_time,_ = create_relative_timestamps(size,heft=True,heft_version=\"dynamic\")\n",
    "eager_time,_ = create_relative_timestamps(size,heft=True,heft_version=\"eager\")\n",
    "print dheft_time, eager_time\n",
    "clustering_time = 0.00664258003235\n",
    "speedup_dheft = dheft_time/clustering_time\n",
    "speedup_eager = eager_time/clustering_time\n",
    "print speedup_dheft, speedup_eager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese 64 2 0.0062267780304 0.00568795204163 [2] [4] 8.65336753838\n",
    "siamese 128 2 0.00678730010986 0.00664258003235 [2] [2] 2.13221863145\n",
    "siamese 256 2 0.00902819633484 0.00841665267944 [3] [5] 6.77370797792\n",
    "resnext 64 32 0.145850658417 0.145695924759 [2] [5] 0.10609047605\n",
    "resnext 128 32 0.250016212463 0.242693662643 [5] [2] 2.92882999378\n",
    "resnext 256 32 0.462659358978 0.443778753281 [2] [3] 4.08088701357"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if folder == \"Expt-2\":\n",
    "    heft_times = []\n",
    "    for size in range(sl,su):\n",
    "        total_time,_ = create_relative_timestamps(size,heft=True,heft_version=heft_version)\n",
    "        heft_times.append(total_time)\n",
    "\n",
    "\n",
    "sizes = np.array(sizes)\n",
    "gains = np.array(gains)\n",
    "gpu_queues = np.array(gpu_queues)\n",
    "cpu_queues = np.array(cpu_queues)\n",
    "if folder == 'Expt-2':\n",
    "    heft_times = np.array(heft_times)\n",
    "    best_times = np.array(best_times)\n",
    "    speedups_over_heft = heft_times/best_times\n",
    "    real_sizes = 2**sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if folder == 'Expt-2':\n",
    "    plt.xlabel(r'Size of Transformer - $\\beta$')\n",
    "    plt.ylabel('Speedup')\n",
    "    plt.plot(real_sizes,speedups_over_heft,'bo-')\n",
    "    #plt.axvline(10.5,color='r',linestyle='dashed')\n",
    "    #plt.title(r'Speedups over HEFT vs Size of Transformer')\n",
    "    plt.xscale('log',basex=2)\n",
    "    plt.xlim(32,1024)\n",
    "    #plt.xticks(real_sizes)\n",
    "    #plt.plot(sizes,cpu_queues,'ro-')\n",
    "\n",
    "\n",
    "    for i in range(len(sizes)):\n",
    "        x = real_sizes[i]\n",
    "        y = speedups_over_heft[i]\n",
    "        if x > 10:\n",
    "            label =  str(gpu_queues[i])+\",\"+str(cpu_queues[i])\n",
    "        else:\n",
    "            label = str(gpu_queues[i])+\",\"+str(0)\n",
    "        y_offset = 10 if i%2 else 10\n",
    "        plt.annotate(label, # this is the text\n",
    "                     (x,y), # this is the point to label\n",
    "                     textcoords=\"offset points\", # how to position the text\n",
    "                     xytext=(-2.5,y_offset), # distance from text to points (x,y)\n",
    "                     ha='center',\n",
    "                     fontsize = 8,\n",
    "                     label = 'cq_config') \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh4AAAF5CAYAAADQ2iM1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nehjSVAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11caf5f50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if folder == 'Expt-1':\n",
    "    gains = np.array(gains)\n",
    "    speedups = 1/(1-gains/100)\n",
    "    plt.xlim(0,17)\n",
    "    plt.xlabel('Number of heads')\n",
    "    plt.ylabel('Speedup')\n",
    "    plt.plot(sizes,speedups,'bo-')\n",
    "    plt.axvline(10.5,color='r',linestyle='dashed')\n",
    "    #plt.title('Speedups vs Number of Heads - (CQ_gpu, CQ_cpu)')\n",
    "    #plt.plot(sizes,cpu_queues,'ro-')\n",
    "\n",
    "\n",
    "    for i in range(len(sizes)):\n",
    "        x = sizes[i]\n",
    "        y = speedups[i]\n",
    "        if x > 10:\n",
    "            label =  str(gpu_queues[i])+\",\"+str(cpu_queues[i])\n",
    "        else:\n",
    "            label = str(gpu_queues[i])+\",\"+str(0)\n",
    "        y_offset = 10 if i%2 else 10\n",
    "        plt.annotate(label, # this is the text\n",
    "                     (x,y), # this is the point to label\n",
    "                     textcoords=\"offset points\", # how to position the text\n",
    "                     xytext=(-2.5,y_offset), # distance from text to points (x,y)\n",
    "                     ha='center',\n",
    "                     fontsize = 8,\n",
    "                     label = 'cq_config') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if folder == 'Expt-2':\n",
    "    best_time,best_timestamps = create_relative_timestamps(size=9,num_queues_gpu=2,num_queues_cpu=2,num_heads_on_cpu=0,folder=folder)\n",
    "    heft_time,heft_timestamps = create_relative_timestamps(size=9,heft=True,heft_version=heft_version)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_time_delta(timestamp):\n",
    "    now = datetime.now()\n",
    "    second = int(timestamp)\n",
    "    microsecond = (timestamp - float(second))*1e6\n",
    "    now = now.replace(hour=0, minute=0, second=second, microsecond=int(microsecond))\n",
    "    return now\n",
    "\n",
    "\n",
    "def plot_per_cq(relative_timestamps,total_time,title):\n",
    "    df = []\n",
    "    kernels = {}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    for kernel,events in relative_timestamps.items():\n",
    "        dev = events[\"device\"]\n",
    "        cq = events[\"cmdq\"]\n",
    "        #print kernel,cq\n",
    "        Task = \"<b>{}_{}</b>\".format(dev,cq)\n",
    "        ##events -> write,read,nd_range\n",
    "        ##event  -> device_queued,device_start,device-end\n",
    "    #         for interval in intervals:\n",
    "    #             Resource=event\n",
    "    #             Start = now + timedelta(seconds=interval[0])\n",
    "    #             Finish = now + timedelta(seconds=interval[1])\n",
    "    #             df.append(dict(Task=Task,Start=Start,Finish=Finish,Resource=Resource))\n",
    "\n",
    "\n",
    "        if events[\"write\"][\"device_start\"] > 0:\n",
    "            write_overhead_start = to_time_delta(events[\"write\"][\"host_queued_start\"])\n",
    "            write_event_start = write_overhead_end = to_time_delta(events[\"write\"][\"device_start\"])\n",
    "            write_event_end = to_time_delta(events[\"write\"][\"device_end\"])\n",
    "            #df.append(dict(Task=Task,Start=write_overhead_start,Finish=write_overhead_end,Resource='overhead'))\n",
    "            df.append(dict(Task=Task,Start=write_event_start,Finish=write_event_end,Resource='<b>write</b>'))\n",
    "\n",
    "\n",
    "\n",
    "        if kernel.startswith('FFC'):\n",
    "            exec_resource = '<b>gemm</b>'\n",
    "        elif \"transpose\" in kernel:\n",
    "            exec_resource = '<b>transpose</b>'\n",
    "        elif 'softmax' in kernel:\n",
    "            exec_resource = '<b>softmax</b>'\n",
    "        else:\n",
    "            exec_resource = '<b>copy</b>'\n",
    "\n",
    "        exec_event_start  = to_time_delta(events[\"nd_range\"][\"device_start\"])\n",
    "        exec_event_end = to_time_delta(events[\"nd_range\"][\"device_end\"])\n",
    "        df.append(dict(Task=Task,Start=exec_event_start,Finish=exec_event_end,Resource=exec_resource))\n",
    "\n",
    "\n",
    "        if events[\"read\"][\"device_start\"] > 0:\n",
    "            read_event_start = to_time_delta(events[\"read\"][\"device_start\"])\n",
    "            read_overhead_start = read_event_end = to_time_delta(events[\"read\"][\"device_end\"])\n",
    "            df.append(dict(Task=Task,Start=read_event_start,Finish=read_event_end,Resource='<b>read</b>'))\n",
    "\n",
    "\n",
    "\n",
    "    colors = {'<b>copy</b>': '#ff00ff',\n",
    "              '<b>read</b>': (1, 0.9, 0.16),\n",
    "              '<b>write</b>': 'rgb(0, 255, 100)',\n",
    "             'overhead': 'rgb(0, 0, 255)',\n",
    "             '<b>gemm</b>': '#dd3069',\n",
    "             '<b>transpose</b>': '#a9a9d9',\n",
    "             '<b>softmax</b>': '#3399cc'}\n",
    "\n",
    "    df.sort(key = lambda x : x['Task'])\n",
    "    fig = ff.create_gantt(df, colors=colors, index_col='Resource', show_colorbar=True,\n",
    "                          group_tasks=True,width=1000,height=600)\n",
    "\n",
    "    fig.layout['xaxis']['tickformat'] = '<b>%-S.%3f</b>'\n",
    "    fig.layout['title'] = title\n",
    "    fig.layout['xaxis_title'] = '<b>Time (seconds)</b>'\n",
    "    fig.layout['yaxis_title'] = '<b>Command Queue</b>'\n",
    "    #fig.layout['xaxis_range']=[to_time_delta(0),to_time_delta(total_time)]\n",
    "    fig.layout['xaxis_range'] = [to_time_delta(0),to_time_delta(max(best_time,heft_time)+0.1)]\n",
    "    #fig.layout['xaxis_range'] = [to_time_delta(0),to_time_delta(1.2)]\n",
    "    #fig.layout['paper_bgcolor'] = 'rgb(255,255,255)'\n",
    "    fig.layout['plot_bgcolor'] = 'rgb(255,255,255)'\n",
    "\n",
    "    fig.layout['xaxis']['linecolor'] = 'rgb(0,0,0)'\n",
    "    fig.layout['xaxis']['mirror'] =True\n",
    "    fig.layout['xaxis']['ticks'] = 'outside'\n",
    "    fig.layout['xaxis']['showline'] = True\n",
    "\n",
    "    fig.layout['yaxis']['linecolor'] = 'rgb(0,0,0)'\n",
    "    fig.layout['yaxis']['mirror'] =True\n",
    "    fig.layout['yaxis']['ticks'] = 'outside'\n",
    "    fig.layout['yaxis']['showline'] = True\n",
    "    \n",
    "    fig.layout['font'] = dict(\n",
    "            family=\"Courier New, monospace\",\n",
    "            size=22,\n",
    "            color=\"#000000\")\n",
    "    fig.update_traces(mode='lines', line_color='black',line_width=0.5,selector=dict(fill='toself'),dy=0.0001,dx=0.0001)\n",
    "\n",
    "    \n",
    "    fig.show()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if folder == \"Expt-2\":\n",
    "    fig = plot_per_cq(best_timestamps,best_time,'Cluster Sch. -  Total Time {0:.2f} s'.format(best_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if folder == \"Expt-2\":\n",
    "    if EXPERIMENT == 2:\n",
    "        title = \"Eager Sch.\"\n",
    "    else:\n",
    "        title = \"HEFT Sch.\"\n",
    "    fig = plot_per_cq(heft_timestamps,heft_time,'{0} - Total Time {1:.2f} s'.format(title,heft_time))\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
